{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPDgdFWcgHJcs20ZdS7YpvL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/QuVin1203/AI_Saturday/blob/main/Week8_PreprocessWithScalar_Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ii-MTLwo0T4s"
      },
      "outputs": [],
      "source": [
        "#libraries of different datasets to train\n",
        "from sklearn import datasets\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "# In machine learning, Output can only have 1 bit but have to display 3 values (0,1,2) => one-hot-encoding make it to the string of 0 and 1 like 0->100 ; 1->010 ; ... make the output values more acurate \n",
        "# StandardScaler makes data \"cung chieu cao\" to be able to train the dataset\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The name of vars must be like this, other ways will not be recognized \n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "print(X[:5])\n",
        "print(y[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbmJpHFb0Xnc",
        "outputId": "4117b9ff-2654-4b53-8c77-6af0321d5611"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[5.1 3.5 1.4 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.  3.6 1.4 0.2]]\n",
            "[0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split datasets to 2 parts: training and testing in order 7:3\n",
        "X_train, X_test, y_train, y_test = train_test_split( X,y,test_size=0.3)"
      ],
      "metadata": {
        "id": "zXFeGfd20aRM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc = StandardScaler()\n",
        "sc.fit(X_train)\n",
        "X_train_std = sc.transform(X_train)\n",
        "X_test_std = sc.transform(X_test)"
      ],
      "metadata": {
        "id": "tmh60nyf0b7V"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Max_iter = số lần học, eta0 = learning rate \n",
        "model = Perceptron (max_iter = 40, eta0 = 0.1, random_state = 0)\n",
        "model.fit( X_train, y_train )\n",
        "y_predict = model.predict(X_test)\n",
        "\n",
        "print(y_test)\n",
        "print(y_predict)\n",
        "print('Prediction accuracy when did not use Scaler is:', accuracy_score(y_test, y_predict))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADBuV6sD0reS",
        "outputId": "e13fe8b5-4891-4db3-d0a9-10671610f1f2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 1 0 0 0 0 2 0 1 2 1 0 0 2 0 2 0 2 0 1 2 1 2 0 1 1 2 0 2 2 1 2 0 1 2 2\n",
            " 1 0 2 1 0 1 0 2]\n",
            "[0 0 1 0 0 0 0 1 1 1 1 1 0 0 1 0 1 0 2 0 1 1 1 1 0 1 1 1 0 1 2 1 2 0 1 2 1\n",
            " 1 0 2 1 0 1 0 2]\n",
            "Prediction accuracy when did not use Scaler is: 0.7777777777777778\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Perceptron (max_iter = 40, eta0 = 0.1, random_state = 0)\n",
        "model.fit( X_train_std, y_train )\n",
        "y_predict = model.predict(X_test_std)\n",
        "\n",
        "print(y_test)\n",
        "print(y_predict)\n",
        "print('Prediction accuracy when  use Scaler is:', accuracy_score(y_test, y_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81_MMLXn0uPB",
        "outputId": "33551675-7332-4505-ea70-a776068884f9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 1 0 0 0 0 2 0 1 2 1 0 0 2 0 2 0 2 0 1 2 1 2 0 1 1 2 0 2 2 1 2 0 1 2 2\n",
            " 1 0 2 1 0 1 0 2]\n",
            "[0 0 1 0 0 0 0 2 1 1 2 2 0 0 2 0 2 0 2 0 1 2 1 2 0 1 1 2 0 2 2 2 2 0 1 2 2\n",
            " 1 0 2 1 0 1 0 2]\n",
            "Prediction accuracy when  use Scaler is: 0.9333333333333333\n"
          ]
        }
      ]
    }
  ]
}